{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3473e093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smile not detected\n",
      "smile detected\n",
      "smile detected\n",
      "smile not detected\n",
      "smile not detected\n",
      "smile not detected\n",
      "smile detected\n",
      "smile not detected\n",
      "smile not detected\n",
      "smile detected\n",
      "smile detected\n",
      "smile detected\n",
      "smile detected\n",
      "smile detected\n",
      "smile detected\n",
      "smile detected\n",
      "smile detected\n",
      "smile detected\n",
      "smile detected\n",
      "smile detected\n",
      "smile not detected\n",
      "smile not detected\n",
      "smile not detected\n",
      "smile not detected\n",
      "smile not detected\n",
      "smile not detected\n",
      "smile not detected\n",
      "smile not detected\n",
      "smile not detected\n",
      "smile not detected\n",
      "smile detected\n",
      "smile not detected\n",
      "smile detected\n",
      "smile detected\n",
      "smile detected\n",
      "smile detected\n",
      "smile detected\n",
      "smile detected\n",
      "smile detected\n",
      "smile detected\n",
      "smile detected\n",
      "smile detected\n",
      "smile detected\n",
      "smile detected\n",
      "smile detected\n",
      "smile detected\n",
      "smile detected\n",
      "smile detected\n",
      "smile detected\n",
      "smile detected\n",
      "smile detected\n",
      "smile detected\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "smile_cascade = cv2.CascadeClassifier('haarcascade_smile.xml')\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while 1:\n",
    "    ret, img = cap.read()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]\n",
    "        \n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "        for (ex,ey,ew,eh) in eyes:\n",
    "            cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "            \n",
    "        smiles = smile_cascade.detectMultiScale(roi_gray, 1.8, 20)\n",
    "        if len(smiles) > 0:\n",
    "            print(\"smile detected\")\n",
    "            for (sx, sy, sw, sh) in smiles:\n",
    "                cv2.rectangle(roi_color, (sx, sy), ((sx + sw), (sy + sh)), (255, 0, 130), 2)\n",
    "                cv2.putText(roi_color, \"smile\", (sx, sy),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "        else:\n",
    "            print(\"smile not detected\")\n",
    "\n",
    "    cv2.imshow('img',img)\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8b1171",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
